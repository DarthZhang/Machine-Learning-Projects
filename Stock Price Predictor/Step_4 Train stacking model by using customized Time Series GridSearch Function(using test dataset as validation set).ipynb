{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('/Users/yanhuan/anaconda/pkgs/seaborn-0.7.1-py27_0/lib/python2.7/site-packages')\n",
    "#import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "SP500=pd.read_csv('SP500_new.csv')\n",
    "Nasdaq=pd.read_csv('Nasdaq_new.csv')\n",
    "DJI=pd.read_csv('DJI_new.csv')\n",
    "DAX=pd.read_csv('DAX_new.csv')\n",
    "Paris=pd.read_csv('Paris_new.csv')\n",
    "Tokyo=pd.read_csv('Tokyo_new.csv')\n",
    "HongKong=pd.read_csv('HongKong_new.csv')\n",
    "Aus=pd.read_csv('Aus_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Target=SP500['Adj Close'].pct_change(1).shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets=[SP500,Nasdaq,DJI,DAX,Paris,Tokyo,HongKong,Aus]\n",
    "namesets=['SP500','Nasdaq','DJI','DAX','Paris','Tokyo','HongKong','Aus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def addFeatures(datasets,DaysRet,DaysRetMovAvg,DaysLags):\n",
    "    \"\"\"\n",
    "    compute dataset's DaysReturns,DaysReturnMovAvg and DaysLags\n",
    "    DaysReturnMovAvg must >=2\n",
    "    \"\"\"\n",
    "    Max=max(DaysRet,DaysRetMovAvg,DaysLags+1)\n",
    "    for i in range(len(datasets)):\n",
    "        dataset=datasets[i]\n",
    "        nameset=namesets[i]\n",
    "        for i in range(1,DaysRet+1):\n",
    "            dataset[nameset+'_'+str(i)+'_'+'DaysRet'] = dataset['Adj Close'].pct_change(i)\n",
    "        for i in range(2,DaysRetMovAvg+1):\n",
    "            dataset[nameset+'_'+str(i)+'_'+'DaysRetMovAvg'] = pd.rolling_mean(dataset[nameset+'_'+str(1)+'_'+'DaysRet'], i)\n",
    "        for i in range(1,DaysLags+1):\n",
    "            dataset[nameset+'_'+str(i)+'_'+'DaysLags'] = dataset[nameset+'_'+str(1)+'_'+'DaysRet'].shift(i)\n",
    "        dataset=dataset[Max:]\n",
    "    return Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:13: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(center=False,window=2).mean()\n",
      "C:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:13: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(center=False,window=3).mean()\n",
      "C:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:13: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(center=False,window=4).mean()\n",
      "C:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:13: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(center=False,window=5).mean()\n",
      "C:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:13: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(center=False,window=6).mean()\n",
      "C:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:13: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(center=False,window=7).mean()\n",
      "C:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:13: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(center=False,window=8).mean()\n",
      "C:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:13: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(center=False,window=9).mean()\n"
     ]
    }
   ],
   "source": [
    "Max=addFeatures(datasets,9,9,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mergedataset(datasets):\n",
    "    useless=['Date','Open','High','Low','Close','Adj Close','Volume']\n",
    "    for i in range(len(datasets)):\n",
    "        datasets[i]=datasets[i].drop(useless, axis = 1)\n",
    "    new_dataset = pd.concat(datasets,axis=1)\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features=mergedataset(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features=features[Max:-1]\n",
    "Target=Target[Max:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transfer Target data to binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Target[Target > 0] = 1\n",
    "Target[Target <= 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train=features[:-500]\n",
    "X_test=features[-500:]\n",
    "y_train=Target[:-500]\n",
    "y_test=Target[-500:]\n",
    "\n",
    "\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(features,Target, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try to predict the the trend of daily return(Classification Problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def GridSearch_TimeSeries(X_train, y_train,X_test,y_test, algorithm,params_fix, params):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    a=params_fix\n",
    "    total={}\n",
    "    for i in range(len(list(params.values())[0])):\n",
    "        for j in range(len(list(params.values())[1])):\n",
    "            a[list(params.keys())[0]]=list(params.values())[0][i]\n",
    "            a[list(params.keys())[1]]=list(params.values())[1][j]\n",
    "        \n",
    "\n",
    "            reg=algorithm(**a)\n",
    "            reg.fit(X_train, y_train)\n",
    "            y_predict=reg.predict(X_test)\n",
    "            accuracy=accuracy_score(y_test,y_predict)\n",
    "            #print(accuracies.mean())\n",
    "            info=[]\n",
    "            info.append(list(params.values())[0][i])\n",
    "            info.append(list(params.values())[1][j])\n",
    "            total[str(accuracy)]=info\n",
    "    compare=[]\n",
    "    for i in total.keys():\n",
    "        compare.append(float(i))\n",
    "    Best_accu=max(compare)\n",
    "    print('Best accuracy:',Best_accu)\n",
    "    print(list(params.keys())[0],':',total[str(Best_accu)][0])\n",
    "    print(list(params.keys())[1],':',total[str(Best_accu)][1])\n",
    "    fin_params=params_fix\n",
    "    fin_params[list(params.keys())[0]]=total[str(Best_accu)][0]\n",
    "    fin_params[list(params.keys())[1]]=total[str(Best_accu)][1]\n",
    "    return fin_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.512\n",
      "min_samples_split : 2\n",
      "n_estimators : 120\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "para=GridSearch_TimeSeries(X_train, y_train,X_test,y_test, RandomForestClassifier,{'random_state':1},{'n_estimators':[120,150],'min_samples_split':[2]})                                                                                                                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 1, 'min_samples_split': 2, 'n_estimators': 120}\n"
     ]
    }
   ],
   "source": [
    "print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=120, n_jobs=1, oob_score=False, random_state=1,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=RandomForestClassifier(**para)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.512\n"
     ]
    }
   ],
   "source": [
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.536\n",
      "min_samples_split : 2\n",
      "n_estimators : 80\n",
      "0.536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "para=GridSearch_TimeSeries(X_train, y_train,X_test,y_test, RandomForestClassifier,{'random_state':1},{'n_estimators':[80,100,120],'min_samples_split':[2]}) \n",
    "\n",
    "model=RandomForestClassifier(**para)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.536\n",
      "min_samples_split : 2\n",
      "n_estimators : 80\n",
      "0.536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "para=GridSearch_TimeSeries(X_train, y_train,X_test,y_test, RandomForestClassifier,{'random_state':1},{'n_estimators':[30,50,70,80],'min_samples_split':[2]}) \n",
    "\n",
    "model=RandomForestClassifier(**para)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.536\n",
      "min_samples_split : 2\n",
      "n_estimators : 80\n",
      "0.536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "para=GridSearch_TimeSeries(X_train, y_train,X_test,y_test, RandomForestClassifier,{'random_state':1},{'n_estimators':[80],'min_samples_split':[2,5,7,9,11]}) \n",
    "\n",
    "model=RandomForestClassifier(**para)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 1, 'min_samples_split': 2, 'n_estimators': 80}\n"
     ]
    }
   ],
   "source": [
    "print(para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.532\n",
      "n_neighbors : 25\n",
      "leaf_size : 30\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "para=GridSearch_TimeSeries(X_train, y_train,X_test,y_test, KNeighborsClassifier,{},{'n_neighbors':[23,24,25,26,27,28],'leaf_size':[30]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=25, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=KNeighborsClassifier(n_neighbors=25)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.532\n"
     ]
    }
   ],
   "source": [
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-38ce5100e029>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpara\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGridSearch_TimeSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mSVC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'random_state'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m700\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m800\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m900\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'degree'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m700\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m800\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m900\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-d6e52d7a276d>\u001b[0m in \u001b[0;36mGridSearch_TimeSeries\u001b[1;34m(X_train, y_train, X_test, y_test, algorithm, params_fix, params)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mreg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0my_predict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0maccuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    254\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "para=GridSearch_TimeSeries(X_train, y_train,X_test,y_test,  SVC,{'random_state':1},{'C':[200,300,400,500,600,700,800,900],'degree':[200,300,400,500,600,700,800,900]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=400, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=900, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model=SVC(C=400,degree=900)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.512\n"
     ]
    }
   ],
   "source": [
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.528\n",
      "learning_rate : 3.5\n",
      "n_estimators : 78\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import  AdaBoostClassifier\n",
    "para=GridSearch_TimeSeries(X_train, y_train,X_test,y_test,  AdaBoostClassifier,{'random_state':1},{'n_estimators':[72,73,74,75,76,77,78],'learning_rate':[2,2.5,3,3.5,4,4.5,5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.528\n"
     ]
    }
   ],
   "source": [
    "model=AdaBoostClassifier(**para)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.528\n",
      "learning_rate : 3.5\n",
      "n_estimators : 100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import  AdaBoostClassifier\n",
    "para=GridSearch_TimeSeries(X_train, y_train,X_test,y_test,  AdaBoostClassifier,{'random_state':1},{'n_estimators':[78,80,85,90,95,100],'learning_rate':[2,2.5,3,3.5,4,4.5,5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.528\n",
      "learning_rate : 3.5\n",
      "n_estimators : 500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import  AdaBoostClassifier\n",
    "para=GridSearch_TimeSeries(X_train, y_train,X_test,y_test,  AdaBoostClassifier,{'random_state':1},{'n_estimators':[100,150,200,250,300,400,500],'learning_rate':[3.5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 1, 'learning_rate': 3.5, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "print(para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model=GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.51\n"
     ]
    }
   ],
   "source": [
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "5.2 Fix learning rate and number of estimators for tuning tree-based parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.522\n",
      "learning_rate : 0.1\n",
      "n_estimators : 50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "para=GridSearch_TimeSeries(X_train, y_train,X_test,y_test, \n",
    "                    GradientBoostingClassifier,\n",
    "                    {'min_samples_split':100,'min_samples_leaf':50,'max_depth':8,'max_features':'sqrt','subsample':0.8,'random_state':10},\n",
    "                    {'n_estimators':[20,30,40,50,60,70,80],'learning_rate':[0.1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.522\n"
     ]
    }
   ],
   "source": [
    "model=GradientBoostingClassifier(**para)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 8, 'random_state': 10, 'min_samples_split': 100, 'learning_rate': 0.1, 'max_features': 'sqrt', 'n_estimators': 50, 'subsample': 0.8, 'min_samples_leaf': 50}\n"
     ]
    }
   ],
   "source": [
    "print(para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3 Tune max_depth and num_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.534\n",
      "max_depth : 9\n",
      "min_samples_split : 1000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "para=GridSearch_TimeSeries(X_train, y_train,X_test,y_test, \n",
    "                    GradientBoostingClassifier,\n",
    "                    {'max_depth': 8, 'random_state': 10, 'min_samples_split': 100, 'learning_rate': 0.1, 'max_features': 'sqrt', 'n_estimators': 50, 'subsample': 0.8, 'min_samples_leaf': 50},\n",
    "                    {'max_depth':[5,7,9,11,13,15],'min_samples_split':[200,400,600,800,1000]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.542\n",
      "max_depth : 10\n",
      "min_samples_split : 1000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "para=GridSearch_TimeSeries(X_train, y_train,X_test,y_test, \n",
    "                    GradientBoostingClassifier,\n",
    "                    {'n_estimators':30,'learning_rate':0.1,'min_samples_leaf':50,'max_features':'sqrt','subsample':0.8,'random_state':10},\n",
    "                    {'max_depth':[8,9,10],'min_samples_split':[1000,1250,1500,1750,2000]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.548\n",
      "max_depth : 9\n",
      "min_samples_split : 1100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "para=GridSearch_TimeSeries(X_train, y_train,X_test,y_test, \n",
    "                    GradientBoostingClassifier,\n",
    "                    {'n_estimators':30,'learning_rate':0.1,'min_samples_leaf':50,'max_features':'sqrt','subsample':0.8,'random_state':10},\n",
    "                    {'max_depth':[9,10,11],'min_samples_split':[900,950,1000,1050,1100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.548\n",
      "max_depth : 9\n",
      "min_samples_split : 1100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "para=GridSearch_TimeSeries(X_train, y_train,X_test,y_test, \n",
    "                    GradientBoostingClassifier,\n",
    "                    {'n_estimators':30,'learning_rate':0.1,'min_samples_leaf':50,'max_features':'sqrt','subsample':0.8,'random_state':10},\n",
    "                    {'max_depth':[7,8,9,10,11],'min_samples_split':[900,950,1000,1050,1100,1200,1300,1400,1500]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 10, 'max_depth': 9, 'min_samples_split': 1100, 'learning_rate': 0.1, 'max_features': 'sqrt', 'n_estimators': 30, 'subsample': 0.8, 'min_samples_leaf': 50}\n"
     ]
    }
   ],
   "source": [
    "print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.548\n"
     ]
    }
   ],
   "source": [
    "model=GradientBoostingClassifier(**para)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.4 Tune min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.548\n",
      "min_samples_split : 1100\n",
      "min_samples_leaf : 50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "para=GridSearch_TimeSeries(X_train, y_train,X_test,y_test, \n",
    "                    GradientBoostingClassifier,\n",
    "                    {'random_state': 10, 'max_depth': 9, 'min_samples_split': 1100, 'learning_rate': 0.1, 'max_features': 'sqrt', 'n_estimators': 30, 'subsample': 0.8, 'min_samples_leaf': 50},\n",
    "                    {'min_samples_split':[1100],'min_samples_leaf':[30,40,50,60,70]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.548\n",
      "min_samples_split : 1100\n",
      "min_samples_leaf : 50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "para=GridSearch_TimeSeries(X_train, y_train,X_test,y_test, \n",
    "                    GradientBoostingClassifier,\n",
    "                    {'random_state': 10, 'max_depth': 9, 'min_samples_split': 1100, 'learning_rate': 0.1, 'max_features': 'sqrt', 'n_estimators': 30, 'subsample': 0.8, 'min_samples_leaf': 50},\n",
    "                    {'min_samples_split':[1100],'min_samples_leaf':[45,47,50,53,55]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 10, 'max_depth': 9, 'min_samples_split': 1100, 'learning_rate': 0.1, 'max_features': 'sqrt', 'n_estimators': 30, 'subsample': 0.8, 'min_samples_leaf': 50}\n"
     ]
    }
   ],
   "source": [
    "print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.548\n"
     ]
    }
   ],
   "source": [
    "model=GradientBoostingClassifier(**para)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.5 Tune max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.544\n",
      "max_features : 9\n",
      "min_samples_leaf : 50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "para=GridSearch_TimeSeries(X_train, y_train,X_test,y_test, \n",
    "                    GradientBoostingClassifier,\n",
    "                    {'random_state': 10, 'max_depth': 9, 'min_samples_split': 1100, 'learning_rate': 0.1, 'max_features': 'sqrt', 'n_estimators': 30, 'subsample': 0.8, 'min_samples_leaf': 50},\n",
    "                    {'min_samples_leaf':[50],'max_features':[7,9,11,13,15,17,19,21]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.54\n",
      "max_features : 17\n",
      "min_samples_leaf : 50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "para=GridSearch_TimeSeries(X_train, y_train,X_test,y_test, \n",
    "                    GradientBoostingClassifier,\n",
    "                    {'random_state': 10, 'max_depth': 9, 'min_samples_split': 1100, 'learning_rate': 0.1, 'max_features': 'sqrt', 'n_estimators': 30, 'subsample': 0.8, 'min_samples_leaf': 50},\n",
    "                    {'min_samples_leaf':[50],'max_features':[17,18,19,20,21,22,23]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.548\n",
      "max_features : sqrt\n",
      "min_samples_leaf : 50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "para=GridSearch_TimeSeries(X_train, y_train,X_test,y_test, \n",
    "                    GradientBoostingClassifier,\n",
    "                    {'random_state': 10, 'max_depth': 9, 'min_samples_split': 1100, 'learning_rate': 0.1, 'max_features': 'sqrt', 'n_estimators': 30, 'subsample': 0.8, 'min_samples_leaf': 50},\n",
    "                    {'min_samples_leaf':[50],'max_features':['sqrt']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 10, 'max_depth': 9, 'min_samples_split': 1100, 'learning_rate': 0.1, 'max_features': 'sqrt', 'n_estimators': 30, 'subsample': 0.8, 'min_samples_leaf': 50}\n"
     ]
    }
   ],
   "source": [
    "print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.548\n"
     ]
    }
   ],
   "source": [
    "model=GradientBoostingClassifier(**para)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.6 Tuning subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.548\n",
      "subsample : 0.8\n",
      "min_samples_leaf : 50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "para=GridSearch_TimeSeries(X_train, y_train,X_test,y_test, \n",
    "                    GradientBoostingClassifier,\n",
    "                    {'random_state': 10, 'max_depth': 9, 'min_samples_split': 1100, 'learning_rate': 0.1, 'max_features': 'sqrt', 'n_estimators': 30, 'subsample': 0.8, 'min_samples_leaf': 50},\n",
    "                    {'subsample':[0.80,0.81,0.82,0.83,0.84,0.85,0.86,0.87,0.88,0.89],'min_samples_leaf':[50]})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.548\n",
      "subsample : 0.8\n",
      "min_samples_leaf : 50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "para=GridSearch_TimeSeries(X_train, y_train,X_test,y_test, \n",
    "                    GradientBoostingClassifier,\n",
    "                    {'random_state': 10, 'max_depth': 9, 'min_samples_split': 1100, 'learning_rate': 0.1, 'max_features': 'sqrt', 'n_estimators': 30, 'subsample': 0.8, 'min_samples_leaf': 50},\n",
    "                    {'subsample':[0.78,0.79,0.80],'min_samples_leaf':[50]})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 10, 'max_depth': 9, 'min_samples_split': 1100, 'learning_rate': 0.1, 'max_features': 'sqrt', 'n_estimators': 30, 'subsample': 0.8, 'min_samples_leaf': 50}\n"
     ]
    }
   ],
   "source": [
    "print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.548\n"
     ]
    }
   ],
   "source": [
    "model=GradientBoostingClassifier(**para)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "5.7 lower learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params={'random_state': 10, 'max_depth': 9, 'min_samples_split': 1100, 'learning_rate': 0.1, 'max_features': 'sqrt', 'n_estimators': 29, 'subsample': 0.8, 'min_samples_leaf': 50}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55\n"
     ]
    }
   ],
   "source": [
    "model=GradientBoostingClassifier(**params)\n",
    "model.fit(X_train, y_train)\n",
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.55\n",
      "learning_rate : 0.1\n",
      "n_estimators : 33\n"
     ]
    }
   ],
   "source": [
    "para=GridSearch_TimeSeries(X_train, y_train,X_test,y_test, \n",
    "                    GradientBoostingClassifier,\n",
    "                    {'random_state': 10, 'max_depth': 9, 'min_samples_split': 1100, 'max_features': 'sqrt','subsample': 0.8, 'min_samples_leaf': 50},\n",
    "                    {'learning_rate':[0.08,0.09,0.1,0.11,0.12],'n_estimators':[25,26,27,28,29,30,31,32,33]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.55\n",
      "learning_rate : 0.1\n",
      "n_estimators : 33\n"
     ]
    }
   ],
   "source": [
    "para=GridSearch_TimeSeries(X_train, y_train,X_test,y_test, \n",
    "                    GradientBoostingClassifier,\n",
    "                    {'random_state': 10, 'max_depth': 9, 'min_samples_split': 1100, 'max_features': 'sqrt','subsample': 0.8, 'min_samples_leaf': 50},\n",
    "                    {'learning_rate':[0.1],'n_estimators':[33,32,31,34,35]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 10, 'max_depth': 9, 'min_samples_split': 1100, 'learning_rate': 0.1, 'max_features': 'sqrt', 'n_estimators': 33, 'subsample': 0.8, 'min_samples_leaf': 50}\n"
     ]
    }
   ],
   "source": [
    "print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=9,\n",
       "              max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=50,\n",
       "              min_samples_split=1100, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=33, presort='auto', random_state=10,\n",
       "              subsample=0.8, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GradientBoostingClassifier(**para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55\n"
     ]
    }
   ],
   "source": [
    "model=GradientBoostingClassifier(**para)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "6 QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\discriminant_analysis.py:695: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
       "               store_covariances=False, tol=0.0001)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "model=QuadraticDiscriminantAnalysis()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.498\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "7 SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.524\n",
      "n_iter : 13\n",
      "l1_ratio : 0.18\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "para=GridSearch_TimeSeries(X_train, y_train,X_test,y_test, SGDClassifier,{'random_state':1},{'n_iter':[3,5,7,10,13,15],'l1_ratio':[0.13,0.14,0.15,0.16,0.17,0.18]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.524\n"
     ]
    }
   ],
   "source": [
    "model=SGDClassifier(**para)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=1.0, learning_rate='optimal',\n",
       "       loss='hinge', n_iter=13, n_jobs=1, penalty='l2', power_t=0.5,\n",
       "       random_state=1, shuffle=True, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGDClassifier(**para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1.GradientBoostingClassifier(criterion='friedman_mse', init=None,                          0.55\n",
    "              learning_rate=0.1, loss='deviance', max_depth=9,\n",
    "              max_features='sqrt', max_leaf_nodes=None,\n",
    "              min_impurity_split=1e-07, min_samples_leaf=50,\n",
    "              min_samples_split=1100, min_weight_fraction_leaf=0.0,\n",
    "              n_estimators=33, presort='auto', random_state=10,\n",
    "              subsample=0.8, verbose=0, warm_start=False)\n",
    "2.RandomForestClassifier(random_state=1, min_samples_split= 2, n_estimators= 80)           0.536\n",
    "3.KNeighborsClassifier(n_neighbors=25)                                                     0.532\n",
    "4.AdaBoostClassifier(random_state=1,n_estimators=100,learning_rate=3.5)                    0.528\n",
    "5.SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,               0.524\n",
    "       eta0=0.0, fit_intercept=True, l1_ratio=1.0, learning_rate='optimal',\n",
    "       loss='hinge', n_iter=13, n_jobs=1, penalty='l2', power_t=0.5,\n",
    "       random_state=1, shuffle=True, verbose=0, warm_start=False)\n",
    "6.SVC(random_state=1,C=400,degree=900)                                                     0.512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator,TransformerMixin, ClassifierMixin\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.linear_model import ElasticNetCV, LassoLarsCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Train the stacked models then predict the test data'''\n",
    "#ORIGINAL\n",
    "class StackingEstimator(BaseEstimator, TransformerMixin):\n",
    "        \n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.estimator.fit(X, y, **fit_params)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = check_array(X)\n",
    "        X_transformed = np.copy(X)\n",
    "        # add class probabilities as a synthetic feature\n",
    "        if issubclass(self.estimator.__class__, ClassifierMixin) and hasattr(self.estimator, 'predict_proba'):\n",
    "            X_transformed = np.hstack((self.estimator.predict_proba(X), X))\n",
    "\n",
    "        # add class prodiction as a synthetic feature\n",
    "        X_transformed = np.hstack((np.reshape(self.estimator.predict(X), (-1, 1)), X_transformed))\n",
    "\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "stacked_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=KNeighborsClassifier(n_neighbors=25)),\n",
    "    StackingEstimator(estimator=RandomForestClassifier(random_state=1, min_samples_split= 2, n_estimators= 80)),\n",
    "    GradientBoostingClassifier(criterion='friedman_mse', init=None,                         \n",
    "              learning_rate=0.1, loss='deviance', max_depth=9,\n",
    "              max_features='sqrt', max_leaf_nodes=None,\n",
    "              min_impurity_split=1e-07, min_samples_leaf=50,\n",
    "              min_samples_split=1100, min_weight_fraction_leaf=0.0,\n",
    "              n_estimators=33, presort='auto', random_state=10,\n",
    "              subsample=0.8, verbose=0, warm_start=False)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.478\n"
     ]
    }
   ],
   "source": [
    "stacked_pipeline.fit(X_train, y_train)\n",
    "y_predict=stacked_pipeline.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Trial_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.538\n"
     ]
    }
   ],
   "source": [
    "stacked_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=AdaBoostClassifier(random_state=1,n_estimators=100,learning_rate=3.5)),\n",
    "    StackingEstimator(estimator=KNeighborsClassifier(n_neighbors=25)),\n",
    "    StackingEstimator(estimator=RandomForestClassifier(random_state=1, min_samples_split= 2, n_estimators= 80)),\n",
    "    GradientBoostingClassifier(criterion='friedman_mse', init=None,                         \n",
    "              learning_rate=0.1, loss='deviance', max_depth=9,\n",
    "              max_features='sqrt', max_leaf_nodes=None,\n",
    "              min_impurity_split=1e-07, min_samples_leaf=50,\n",
    "              min_samples_split=1100, min_weight_fraction_leaf=0.0,\n",
    "              n_estimators=33, presort='auto', random_state=10,\n",
    "              subsample=0.8, verbose=0, warm_start=False)\n",
    "\n",
    ")\n",
    "\n",
    "stacked_pipeline.fit(X_train, y_train)\n",
    "y_predict=stacked_pipeline.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.468\n"
     ]
    }
   ],
   "source": [
    "stacked_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
    "       eta0=0.0, fit_intercept=True, l1_ratio=1.0, learning_rate='optimal',\n",
    "       loss='hinge', n_iter=13, n_jobs=1, penalty='l2', power_t=0.5,\n",
    "       random_state=1, shuffle=True, verbose=0, warm_start=False)),\n",
    "    StackingEstimator(estimator=AdaBoostClassifier(random_state=1,n_estimators=100,learning_rate=3.5)),\n",
    "    StackingEstimator(estimator=KNeighborsClassifier(n_neighbors=25)),\n",
    "    StackingEstimator(estimator=RandomForestClassifier(random_state=1, min_samples_split= 2, n_estimators= 80)),\n",
    "    GradientBoostingClassifier(criterion='friedman_mse', init=None,                         \n",
    "              learning_rate=0.1, loss='deviance', max_depth=9,\n",
    "              max_features='sqrt', max_leaf_nodes=None,\n",
    "              min_impurity_split=1e-07, min_samples_leaf=50,\n",
    "              min_samples_split=1100, min_weight_fraction_leaf=0.0,\n",
    "              n_estimators=33, presort='auto', random_state=10,\n",
    "              subsample=0.8, verbose=0, warm_start=False)\n",
    "\n",
    ")\n",
    "\n",
    "stacked_pipeline.fit(X_train, y_train)\n",
    "y_predict=stacked_pipeline.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Trial_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.498\n"
     ]
    }
   ],
   "source": [
    "stacked_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=SVC(random_state=1,C=400,degree=900)),\n",
    "    StackingEstimator(estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
    "       eta0=0.0, fit_intercept=True, l1_ratio=1.0, learning_rate='optimal',\n",
    "       loss='hinge', n_iter=13, n_jobs=1, penalty='l2', power_t=0.5,\n",
    "       random_state=1, shuffle=True, verbose=0, warm_start=False)),\n",
    "    StackingEstimator(estimator=AdaBoostClassifier(random_state=1,n_estimators=100,learning_rate=3.5)),\n",
    "    StackingEstimator(estimator=KNeighborsClassifier(n_neighbors=25)),\n",
    "    StackingEstimator(estimator=RandomForestClassifier(random_state=1, min_samples_split= 2, n_estimators= 80)),\n",
    "    GradientBoostingClassifier(criterion='friedman_mse', init=None,                         \n",
    "              learning_rate=0.1, loss='deviance', max_depth=9,\n",
    "              max_features='sqrt', max_leaf_nodes=None,\n",
    "              min_impurity_split=1e-07, min_samples_leaf=50,\n",
    "              min_samples_split=1100, min_weight_fraction_leaf=0.0,\n",
    "              n_estimators=33, presort='auto', random_state=10,\n",
    "              subsample=0.8, verbose=0, warm_start=False)\n",
    "\n",
    ")\n",
    "\n",
    "stacked_pipeline.fit(X_train, y_train)\n",
    "y_predict=stacked_pipeline.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Stacking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacked_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=AdaBoostClassifier(random_state=1,n_estimators=100,learning_rate=3.5)),\n",
    "    StackingEstimator(estimator=KNeighborsClassifier(n_neighbors=25)),\n",
    "    StackingEstimator(estimator=RandomForestClassifier(random_state=1, min_samples_split= 2, n_estimators= 80)),\n",
    "    GradientBoostingClassifier(criterion='friedman_mse', init=None,                         \n",
    "              learning_rate=0.1, loss='deviance', max_depth=9,\n",
    "              max_features='sqrt', max_leaf_nodes=None,\n",
    "              min_impurity_split=1e-07, min_samples_leaf=50,\n",
    "              min_samples_split=1100, min_weight_fraction_leaf=0.0,\n",
    "              n_estimators=33, presort='auto', random_state=10,\n",
    "              subsample=0.8, verbose=0, warm_start=False)\n",
    "\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
