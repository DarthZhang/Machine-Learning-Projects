{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('/Users/yanhuan/anaconda/pkgs/seaborn-0.7.1-py27_0/lib/python2.7/site-packages')\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "SP500=pd.read_csv('SP500_new.csv')\n",
    "Nasdaq=pd.read_csv('Nasdaq_new.csv')\n",
    "DJI=pd.read_csv('DJI_new.csv')\n",
    "DAX=pd.read_csv('DAX_new.csv')\n",
    "Paris=pd.read_csv('Paris_new.csv')\n",
    "Tokyo=pd.read_csv('Tokyo_new.csv')\n",
    "HongKong=pd.read_csv('HongKong_new.csv')\n",
    "Aus=pd.read_csv('Aus_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Target=SP500['Adj Close'].pct_change(1).shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets=[SP500,Nasdaq,DJI,DAX,Paris,Tokyo,HongKong,Aus]\n",
    "namesets=['SP500','Nasdaq','DJI','DAX','Paris','Tokyo','HongKong','Aus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this fuction is used for feature engineering,to be specific,make Multiple Day Returns,Returns Moving Average and Time Lagged Returns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def addFeatures(datasets,DaysRet,DaysRetMovAvg,DaysLags):\n",
    "    \"\"\"\n",
    "    compute dataset's DaysReturns,DaysReturnMovAvg and DaysLags\n",
    "    DaysReturnMovAvg must >=2\n",
    "    \"\"\"\n",
    "    Max=max(DaysRet,DaysRetMovAvg,DaysLags+1)\n",
    "    for i in range(len(datasets)):\n",
    "        dataset=datasets[i]\n",
    "        nameset=namesets[i]\n",
    "        for i in range(1,DaysRet+1):\n",
    "            dataset[nameset+'_'+str(i)+'_'+'DaysRet'] = dataset['Adj Close'].pct_change(i)\n",
    "        for i in range(2,DaysRetMovAvg+1):\n",
    "            dataset[nameset+'_'+str(i)+'_'+'DaysRetMovAvg'] = pd.rolling_mean(dataset[nameset+'_'+str(1)+'_'+'DaysRet'], i)\n",
    "        for i in range(1,DaysLags+1):\n",
    "            dataset[nameset+'_'+str(i)+'_'+'DaysLags'] = dataset[nameset+'_'+str(1)+'_'+'DaysRet'].shift(i)\n",
    "        dataset=dataset[Max:]\n",
    "    return Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanhuan/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:13: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=2,center=False).mean()\n",
      "  del sys.path[0]\n",
      "/Users/yanhuan/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:13: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=3,center=False).mean()\n",
      "  del sys.path[0]\n",
      "/Users/yanhuan/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:13: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=4,center=False).mean()\n",
      "  del sys.path[0]\n",
      "/Users/yanhuan/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:13: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=5,center=False).mean()\n",
      "  del sys.path[0]\n",
      "/Users/yanhuan/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:13: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=6,center=False).mean()\n",
      "  del sys.path[0]\n",
      "/Users/yanhuan/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:13: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=7,center=False).mean()\n",
      "  del sys.path[0]\n",
      "/Users/yanhuan/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:13: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=8,center=False).mean()\n",
      "  del sys.path[0]\n",
      "/Users/yanhuan/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:13: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=9,center=False).mean()\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "Max=addFeatures(datasets,9,9,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mergedataset(datasets):\n",
    "    useless=['Date','Open','High','Low','Close','Adj Close','Volume']\n",
    "    for i in range(len(datasets)):\n",
    "        datasets[i]=datasets[i].drop(useless, axis = 1)\n",
    "    new_dataset = pd.concat(datasets,axis=1)\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features=mergedataset(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features=features[Max:-1]\n",
    "Target=Target[Max:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SP500_1_DaysRet</th>\n",
       "      <th>SP500_2_DaysRet</th>\n",
       "      <th>SP500_3_DaysRet</th>\n",
       "      <th>SP500_4_DaysRet</th>\n",
       "      <th>SP500_5_DaysRet</th>\n",
       "      <th>SP500_6_DaysRet</th>\n",
       "      <th>SP500_7_DaysRet</th>\n",
       "      <th>SP500_8_DaysRet</th>\n",
       "      <th>SP500_9_DaysRet</th>\n",
       "      <th>SP500_2_DaysRetMovAvg</th>\n",
       "      <th>...</th>\n",
       "      <th>Aus_9_DaysRetMovAvg</th>\n",
       "      <th>Aus_1_DaysLags</th>\n",
       "      <th>Aus_2_DaysLags</th>\n",
       "      <th>Aus_3_DaysLags</th>\n",
       "      <th>Aus_4_DaysLags</th>\n",
       "      <th>Aus_5_DaysLags</th>\n",
       "      <th>Aus_6_DaysLags</th>\n",
       "      <th>Aus_7_DaysLags</th>\n",
       "      <th>Aus_8_DaysLags</th>\n",
       "      <th>Aus_9_DaysLags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.008036</td>\n",
       "      <td>0.009905</td>\n",
       "      <td>0.013110</td>\n",
       "      <td>0.020076</td>\n",
       "      <td>0.007630</td>\n",
       "      <td>0.014865</td>\n",
       "      <td>0.009641</td>\n",
       "      <td>0.024037</td>\n",
       "      <td>0.038977</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003458</td>\n",
       "      <td>-0.010261</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>-0.000455</td>\n",
       "      <td>0.005798</td>\n",
       "      <td>-0.012021</td>\n",
       "      <td>-0.010294</td>\n",
       "      <td>-0.001675</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>-0.001689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.011699</td>\n",
       "      <td>0.019828</td>\n",
       "      <td>0.021720</td>\n",
       "      <td>0.024962</td>\n",
       "      <td>0.032010</td>\n",
       "      <td>0.019418</td>\n",
       "      <td>0.026738</td>\n",
       "      <td>0.021452</td>\n",
       "      <td>0.036017</td>\n",
       "      <td>0.009867</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004062</td>\n",
       "      <td>-0.013848</td>\n",
       "      <td>-0.010261</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>-0.000455</td>\n",
       "      <td>0.005798</td>\n",
       "      <td>-0.012021</td>\n",
       "      <td>-0.010294</td>\n",
       "      <td>-0.001675</td>\n",
       "      <td>0.009623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.005317</td>\n",
       "      <td>0.006319</td>\n",
       "      <td>0.014406</td>\n",
       "      <td>0.016287</td>\n",
       "      <td>0.019512</td>\n",
       "      <td>0.026522</td>\n",
       "      <td>0.013997</td>\n",
       "      <td>0.021278</td>\n",
       "      <td>0.016021</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002841</td>\n",
       "      <td>0.004190</td>\n",
       "      <td>-0.013848</td>\n",
       "      <td>-0.010261</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>-0.000455</td>\n",
       "      <td>0.005798</td>\n",
       "      <td>-0.012021</td>\n",
       "      <td>-0.010294</td>\n",
       "      <td>-0.001675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.017507</td>\n",
       "      <td>-0.022731</td>\n",
       "      <td>-0.011299</td>\n",
       "      <td>-0.003354</td>\n",
       "      <td>-0.001505</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.008551</td>\n",
       "      <td>-0.003755</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>-0.011412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001098</td>\n",
       "      <td>0.009310</td>\n",
       "      <td>0.004190</td>\n",
       "      <td>-0.013848</td>\n",
       "      <td>-0.010261</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>-0.000455</td>\n",
       "      <td>0.005798</td>\n",
       "      <td>-0.012021</td>\n",
       "      <td>-0.010294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.002578</td>\n",
       "      <td>-0.020041</td>\n",
       "      <td>-0.025251</td>\n",
       "      <td>-0.013848</td>\n",
       "      <td>-0.005923</td>\n",
       "      <td>-0.004080</td>\n",
       "      <td>-0.000919</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>-0.006324</td>\n",
       "      <td>-0.010043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001073</td>\n",
       "      <td>0.005397</td>\n",
       "      <td>0.009310</td>\n",
       "      <td>0.004190</td>\n",
       "      <td>-0.013848</td>\n",
       "      <td>-0.010261</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>-0.000455</td>\n",
       "      <td>0.005798</td>\n",
       "      <td>-0.012021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SP500_1_DaysRet  SP500_2_DaysRet  SP500_3_DaysRet  SP500_4_DaysRet  \\\n",
       "10         0.008036         0.009905         0.013110         0.020076   \n",
       "11         0.011699         0.019828         0.021720         0.024962   \n",
       "12        -0.005317         0.006319         0.014406         0.016287   \n",
       "13        -0.017507        -0.022731        -0.011299        -0.003354   \n",
       "14        -0.002578        -0.020041        -0.025251        -0.013848   \n",
       "\n",
       "    SP500_5_DaysRet  SP500_6_DaysRet  SP500_7_DaysRet  SP500_8_DaysRet  \\\n",
       "10         0.007630         0.014865         0.009641         0.024037   \n",
       "11         0.032010         0.019418         0.026738         0.021452   \n",
       "12         0.019512         0.026522         0.013997         0.021278   \n",
       "13        -0.001505         0.001663         0.008551        -0.003755   \n",
       "14        -0.005923        -0.004080        -0.000919         0.005950   \n",
       "\n",
       "    SP500_9_DaysRet  SP500_2_DaysRetMovAvg       ...        \\\n",
       "10         0.038977               0.004945       ...         \n",
       "11         0.036017               0.009867       ...         \n",
       "12         0.016021               0.003191       ...         \n",
       "13         0.003398              -0.011412       ...         \n",
       "14        -0.006324              -0.010043       ...         \n",
       "\n",
       "    Aus_9_DaysRetMovAvg  Aus_1_DaysLags  Aus_2_DaysLags  Aus_3_DaysLags  \\\n",
       "10            -0.003458       -0.010261        0.002011       -0.000455   \n",
       "11            -0.004062       -0.013848       -0.010261        0.002011   \n",
       "12            -0.002841        0.004190       -0.013848       -0.010261   \n",
       "13            -0.001098        0.009310        0.004190       -0.013848   \n",
       "14            -0.001073        0.005397        0.009310        0.004190   \n",
       "\n",
       "    Aus_4_DaysLags  Aus_5_DaysLags  Aus_6_DaysLags  Aus_7_DaysLags  \\\n",
       "10        0.005798       -0.012021       -0.010294       -0.001675   \n",
       "11       -0.000455        0.005798       -0.012021       -0.010294   \n",
       "12        0.002011       -0.000455        0.005798       -0.012021   \n",
       "13       -0.010261        0.002011       -0.000455        0.005798   \n",
       "14       -0.013848       -0.010261        0.002011       -0.000455   \n",
       "\n",
       "    Aus_8_DaysLags  Aus_9_DaysLags  \n",
       "10        0.009623       -0.001689  \n",
       "11       -0.001675        0.009623  \n",
       "12       -0.010294       -0.001675  \n",
       "13       -0.012021       -0.010294  \n",
       "14        0.005798       -0.012021  \n",
       "\n",
       "[5 rows x 208 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SP500_1_DaysRet</th>\n",
       "      <th>SP500_2_DaysRet</th>\n",
       "      <th>SP500_3_DaysRet</th>\n",
       "      <th>SP500_4_DaysRet</th>\n",
       "      <th>SP500_5_DaysRet</th>\n",
       "      <th>SP500_6_DaysRet</th>\n",
       "      <th>SP500_7_DaysRet</th>\n",
       "      <th>SP500_8_DaysRet</th>\n",
       "      <th>SP500_9_DaysRet</th>\n",
       "      <th>SP500_2_DaysRetMovAvg</th>\n",
       "      <th>...</th>\n",
       "      <th>Aus_9_DaysRetMovAvg</th>\n",
       "      <th>Aus_1_DaysLags</th>\n",
       "      <th>Aus_2_DaysLags</th>\n",
       "      <th>Aus_3_DaysLags</th>\n",
       "      <th>Aus_4_DaysLags</th>\n",
       "      <th>Aus_5_DaysLags</th>\n",
       "      <th>Aus_6_DaysLags</th>\n",
       "      <th>Aus_7_DaysLags</th>\n",
       "      <th>Aus_8_DaysLags</th>\n",
       "      <th>Aus_9_DaysLags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5026</th>\n",
       "      <td>-0.006697</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>-0.000365</td>\n",
       "      <td>-0.001360</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001788</td>\n",
       "      <td>0.005404</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>-0.012119</td>\n",
       "      <td>0.010584</td>\n",
       "      <td>0.016732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>-0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5027</th>\n",
       "      <td>-0.000583</td>\n",
       "      <td>-0.007275</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>-0.000947</td>\n",
       "      <td>-0.001942</td>\n",
       "      <td>0.002560</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>-0.003640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.008251</td>\n",
       "      <td>0.005404</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>-0.012119</td>\n",
       "      <td>0.010584</td>\n",
       "      <td>0.016732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.001659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5028</th>\n",
       "      <td>-0.000456</td>\n",
       "      <td>-0.001038</td>\n",
       "      <td>-0.007728</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>-0.002397</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>-0.000519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>-0.015910</td>\n",
       "      <td>-0.008251</td>\n",
       "      <td>0.005404</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>-0.012119</td>\n",
       "      <td>0.010584</td>\n",
       "      <td>0.016732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5029</th>\n",
       "      <td>0.001561</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>-0.006179</td>\n",
       "      <td>0.002117</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>-0.000840</td>\n",
       "      <td>0.003668</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>-0.015910</td>\n",
       "      <td>-0.008251</td>\n",
       "      <td>0.005404</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>-0.012119</td>\n",
       "      <td>0.010584</td>\n",
       "      <td>0.016732</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5030</th>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>-0.005865</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>-0.000525</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000980</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>-0.015910</td>\n",
       "      <td>-0.008251</td>\n",
       "      <td>0.005404</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>-0.012119</td>\n",
       "      <td>0.010584</td>\n",
       "      <td>0.016732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SP500_1_DaysRet  SP500_2_DaysRet  SP500_3_DaysRet  SP500_4_DaysRet  \\\n",
       "5026        -0.006697         0.001595         0.001879        -0.000365   \n",
       "5027        -0.000583        -0.007275         0.001011         0.001295   \n",
       "5028        -0.000456        -0.001038        -0.007728         0.000555   \n",
       "5029         0.001561         0.001104         0.000521        -0.006179   \n",
       "5030         0.000316         0.001877         0.001421         0.000837   \n",
       "\n",
       "      SP500_5_DaysRet  SP500_6_DaysRet  SP500_7_DaysRet  SP500_8_DaysRet  \\\n",
       "5026        -0.001360         0.003145         0.002163         0.001331   \n",
       "5027        -0.000947        -0.001942         0.002560         0.001579   \n",
       "5028         0.000839        -0.001403        -0.002397         0.002103   \n",
       "5029         0.002117         0.002401         0.000156        -0.000840   \n",
       "5030        -0.005865         0.002433         0.002717         0.000472   \n",
       "\n",
       "      SP500_9_DaysRet  SP500_2_DaysRetMovAvg       ...        \\\n",
       "5026         0.001599               0.000825       ...         \n",
       "5027         0.000748              -0.003640       ...         \n",
       "5028         0.001123              -0.000519       ...         \n",
       "5029         0.003668               0.000553       ...         \n",
       "5030        -0.000525               0.000938       ...         \n",
       "\n",
       "      Aus_9_DaysRetMovAvg  Aus_1_DaysLags  Aus_2_DaysLags  Aus_3_DaysLags  \\\n",
       "5026             0.001788        0.005404        0.001874       -0.012119   \n",
       "5027            -0.000164       -0.008251        0.005404        0.001874   \n",
       "5028             0.000603       -0.015910       -0.008251        0.005404   \n",
       "5029             0.000796        0.007113       -0.015910       -0.008251   \n",
       "5030            -0.000980        0.001735        0.007113       -0.015910   \n",
       "\n",
       "      Aus_4_DaysLags  Aus_5_DaysLags  Aus_6_DaysLags  Aus_7_DaysLags  \\\n",
       "5026        0.010584        0.016732        0.000000        0.000211   \n",
       "5027       -0.012119        0.010584        0.016732        0.000000   \n",
       "5028        0.001874       -0.012119        0.010584        0.016732   \n",
       "5029        0.005404        0.001874       -0.012119        0.010584   \n",
       "5030       -0.008251        0.005404        0.001874       -0.012119   \n",
       "\n",
       "      Aus_8_DaysLags  Aus_9_DaysLags  \n",
       "5026        0.001659       -0.000053  \n",
       "5027        0.000211        0.001659  \n",
       "5028        0.000000        0.000211  \n",
       "5029        0.016732        0.000000  \n",
       "5030        0.010584        0.016732  \n",
       "\n",
       "[5 rows x 208 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train=features[:-500]\n",
    "X_test=features[-500:]\n",
    "y_train=Target[:-500]\n",
    "y_test=Target[-500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1,try to predict the exact daily return(Regression Problem)\n",
    "using train_predict pipeline to choose the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Import two metrics from sklearn - fbeta_score and accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def train_predict(learner, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "\n",
    "    \n",
    "    results = {}\n",
    "    learner = learner.fit(X_train,y_train)\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    # TODO: Compute accuracy on test set\n",
    "    results['R2_test'] = r2_score(y_test,predictions_test)\n",
    "        \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# TODO: Initialize the three models\n",
    "clf_A = linear_model.Ridge (random_state=1)\n",
    "clf_B = svm.SVR(kernel='linear')\n",
    "clf_C = svm.SVR(kernel='rbf')\n",
    "clf_D=AdaBoostRegressor(random_state=1)\n",
    "clf_E=RandomForestRegressor(random_state=1)\n",
    "clf_F = linear_model.Lasso(random_state=1)\n",
    "clf_G =  ElasticNet(random_state=1)\n",
    "\n",
    "\n",
    "# Collect results on the learners\n",
    "results = {}\n",
    "for clf in [clf_A, clf_B, clf_C, clf_D, clf_E,clf_F,clf_G]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ridge': {'R2_test': -0.063548623767675005}, 'AdaBoostRegressor': {'R2_test': -0.010078531724320383}, 'RandomForestRegressor': {'R2_test': -0.12367595592000424}, 'ElasticNet': {'R2_test': -0.0024767043136966205}, 'SVR': {'R2_test': -0.14439830203484694}, 'Lasso': {'R2_test': -0.0024767043136966205}}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "\n",
    "def fit_model(X, y):\n",
    "    \"\"\" Performs grid search over the 'max_depth' parameter for a \n",
    "        decision tree regressor trained on the input data [X, y]. \"\"\"\n",
    "    \n",
    "    # Create cross-validation sets from the training data\n",
    "    # For Balance Data\n",
    "    cv_sets = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.20, random_state = 0)\n",
    "    \n",
    "    \n",
    "    regressor = linear_model.Ridge(random_state=0)\n",
    "\n",
    "   \n",
    "    params = {'alpha':range(145,155,1)}\n",
    "\n",
    "    # TODO: Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "    scoring_fnc = make_scorer(r2_score)\n",
    "\n",
    "    # TODO: Create the grid search object\n",
    "    grid =GridSearchCV(regressor, params,scoring_fnc,cv=cv_sets)\n",
    "    \n",
    "    # Fit the grid search object to the data to compute the optimal model\n",
    "    grid = grid.fit(X, y)\n",
    "\n",
    "    # Return the optimal model after fitting the data\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=fit_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n"
     ]
    }
   ],
   "source": [
    "print(model.get_params()['alpha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00358043329235\n"
     ]
    }
   ],
   "source": [
    "y_predict=model.predict(X_test)\n",
    "print(r2_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2,try to predict the the Movement of  daily return(Classification Problem)\n",
    "using train_predict pipeline to choose the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transfer Target data to binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Target[Target > 0] = 1\n",
    "Target[Target <= 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=features[:-500]\n",
    "X_test=features[-500:]\n",
    "y_train=Target[:-500]\n",
    "y_test=Target[-500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.498\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "reg= RandomForestClassifier(n_estimators=1000)\n",
    "reg.fit(X_train, y_train)\n",
    "pre=reg.predict(X_test)\n",
    "result = accuracy_score(y_test,pre)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Import two metrics from sklearn - fbeta_score and accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def train_predict(learner, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "\n",
    "    \n",
    "    results = {}\n",
    "    learner = learner.fit(X_train,y_train)\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    # TODO: Compute accuracy on test set\n",
    "    results['accuracy_score'] = accuracy_score(y_test,predictions_test)\n",
    "        \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# TODO: Initialize the three models\n",
    "clf_A = RandomForestClassifier(n_estimators=10)\n",
    "clf_B = KNeighborsClassifier()\n",
    "clf_C = SVC()\n",
    "clf_D=AdaBoostClassifier()\n",
    "clf_E=GradientBoostingClassifier(n_estimators=100)\n",
    "clf_F = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "\n",
    "\n",
    "# Collect results on the learners\n",
    "results = {}\n",
    "for clf in [clf_A, clf_B, clf_C, clf_D, clf_E,clf_F]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KNeighborsClassifier': {'accuracy_score': 0.504}, 'RandomForestClassifier': {'accuracy_score': 0.47999999999999998}, 'AdaBoostClassifier': {'accuracy_score': 0.47599999999999998}, 'SVC': {'accuracy_score': 0.51200000000000001}, 'SGDClassifier': {'accuracy_score': 0.49199999999999999}, 'GradientBoostingClassifier': {'accuracy_score': 0.51000000000000001}}\n"
     ]
    }
   ],
   "source": [
    "# when addFeatures(datasets,3,3,3)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KNeighborsClassifier': {'accuracy_score': 0.504}, 'RandomForestClassifier': {'accuracy_score': 0.47999999999999998}, 'AdaBoostClassifier': {'accuracy_score': 0.47599999999999998}, 'SVC': {'accuracy_score': 0.51200000000000001}, 'SGDClassifier': {'accuracy_score': 0.49199999999999999}, 'GradientBoostingClassifier': {'accuracy_score': 0.51000000000000001}}\n"
     ]
    }
   ],
   "source": [
    "# when addFeatures(datasets,9,9,9)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "import numpy as np\n",
    "\n",
    "def fit_model(X, y):\n",
    "    \"\"\" Performs grid search over the 'max_depth' parameter for a \n",
    "        decision tree regressor trained on the input data [X, y]. \"\"\"\n",
    "    \n",
    "    # Create cross-validation sets from the training data\n",
    "    # For Balance Data\n",
    "    cv_sets = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.20, random_state = 0)\n",
    "    \n",
    "    \n",
    "    regressor = SVC(random_state=0)\n",
    "\n",
    "   \n",
    "    params = {'C':[0.3,0.5,0.7,1.0,1.3,1.5,1.7,2.0],'degree':[2,3,4,5,6,7,8],'kernel':[ 'linear', 'poly', 'rbf', 'sigmoid']}\n",
    "\n",
    "    # TODO: Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "    scoring_fnc = make_scorer(accuracy_score)\n",
    "\n",
    "    # TODO: Create the grid search object\n",
    "    grid =GridSearchCV(regressor, params,scoring_fnc,cv=cv_sets)\n",
    "    \n",
    "    # Fit the grid search object to the data to compute the optimal model\n",
    "    grid = grid.fit(X, y)\n",
    "\n",
    "    # Return the optimal model after fitting the data\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=fit_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n",
      "2\n",
      "linear\n"
     ]
    }
   ],
   "source": [
    "print(model.get_params()['C'])\n",
    "print(model.get_params()['degree'])\n",
    "print(model.get_params()['kernel'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.512\n"
     ]
    }
   ],
   "source": [
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
