{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('/Users/yanhuan/anaconda/pkgs/seaborn-0.7.1-py27_0/lib/python2.7/site-packages')\n",
    "#import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "SP500=pd.read_csv('SP500_new.csv')\n",
    "Nasdaq=pd.read_csv('Nasdaq_new.csv')\n",
    "DJI=pd.read_csv('DJI_new.csv')\n",
    "DAX=pd.read_csv('DAX_new.csv')\n",
    "Paris=pd.read_csv('Paris_new.csv')\n",
    "Tokyo=pd.read_csv('Tokyo_new.csv')\n",
    "HongKong=pd.read_csv('HongKong_new.csv')\n",
    "Aus=pd.read_csv('Aus_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Target=SP500['Adj Close'].pct_change(1).shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets=[SP500,Nasdaq,DJI,DAX,Paris,Tokyo,HongKong,Aus]\n",
    "namesets=['SP500','Nasdaq','DJI','DAX','Paris','Tokyo','HongKong','Aus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def addFeatures(datasets,DaysRet,DaysRetMovAvg,DaysLags):\n",
    "    \"\"\"\n",
    "    compute dataset's DaysReturns,DaysReturnMovAvg and DaysLags\n",
    "    DaysReturnMovAvg must >=2\n",
    "    \"\"\"\n",
    "    Max=max(DaysRet,DaysRetMovAvg,DaysLags+1)\n",
    "    for i in range(len(datasets)):\n",
    "        dataset=datasets[i]\n",
    "        nameset=namesets[i]\n",
    "        for i in range(1,DaysRet+1):\n",
    "            dataset[nameset+'_'+str(i)+'_'+'DaysRet'] = dataset['Adj Close'].pct_change(i)\n",
    "        for i in range(2,DaysRetMovAvg+1):\n",
    "            dataset[nameset+'_'+str(i)+'_'+'DaysRetMovAvg'] = pd.rolling_mean(dataset[nameset+'_'+str(1)+'_'+'DaysRet'], i)\n",
    "        for i in range(1,DaysLags+1):\n",
    "            dataset[nameset+'_'+str(i)+'_'+'DaysLags'] = dataset[nameset+'_'+str(1)+'_'+'DaysRet'].shift(i)\n",
    "        dataset=dataset[Max:]\n",
    "    return Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:13: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=2,center=False).mean()\n",
      "C:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:13: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=3,center=False).mean()\n",
      "C:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:13: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=4,center=False).mean()\n",
      "C:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:13: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=5,center=False).mean()\n",
      "C:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:13: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=6,center=False).mean()\n",
      "C:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:13: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=7,center=False).mean()\n",
      "C:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:13: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=8,center=False).mean()\n",
      "C:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:13: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=9,center=False).mean()\n"
     ]
    }
   ],
   "source": [
    "Max=addFeatures(datasets,9,9,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mergedataset(datasets):\n",
    "    useless=['Date','Open','High','Low','Close','Adj Close','Volume']\n",
    "    for i in range(len(datasets)):\n",
    "        datasets[i]=datasets[i].drop(useless, axis = 1)\n",
    "    new_dataset = pd.concat(datasets,axis=1)\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features=mergedataset(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features=features[Max:-1]\n",
    "Target=Target[Max:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transfer Target data to binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Target[Target > 0] = 1\n",
    "Target[Target <= 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train=features[:-500]\n",
    "X_test=features[-500:]\n",
    "y_train=Target[:-500]\n",
    "y_test=Target[-500:]\n",
    "\n",
    "\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(features,Target, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def performTimeSeriesCV(X_train, y_train, number_folds, algorithm,params_fix, params):\n",
    "    \"\"\"\n",
    "    This is cumtomised gridsearch function for time series problem.the tradional grid search randomly spit the dataset which is not suitable for time series problem as it stricctly requires using old data to predict new data! Thus,I make this time series gridsearch function,it goes in this way:\n",
    "    1.Split train set in \" number_folds\" consecutive time folds.\n",
    "    2.Then, in order not lo lose the time information, perform the following steps:\n",
    "    3.Train on fold 1 –>  Test on fold 2\n",
    "    4.Train on fold 1+2 –>  Test on fold 3\n",
    "    5.Train on fold 1+2+3 –>  Test on fold 4\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    n.Train on fold 1+2+3+...+ \"number_folds-1\" –>  Test on fold \"number_folds\" \n",
    "    n+1.Compute the average of the accuracies of the \"number_folds-1\" test folds \n",
    "    \"\"\"\n",
    "    \n",
    "    a=params_fix\n",
    "    total={}\n",
    "    for i in range(len(list(params.values())[0])):\n",
    "        for j in range(len(list(params.values())[1])):\n",
    "            a[list(params.keys())[0]]=list(params.values())[0][i]\n",
    "            a[list(params.keys())[1]]=list(params.values())[1][j]\n",
    "            k = int(np.floor(float(X_train.shape[0]) / number_folds))\n",
    "            accuracies = np.zeros(number_folds-1)\n",
    "            for t in range(2, number_folds + 1):\n",
    "                split = float(t-1)/t\n",
    "         \n",
    "                X = X_train[:(k*t)]\n",
    "                y = y_train[:(k*t)]\n",
    "\n",
    "                index = int(np.floor(X.shape[0] * split))\n",
    "           \n",
    "                X_trainFolds = X[:index]        \n",
    "                y_trainFolds = y[:index]\n",
    "\n",
    "                X_testFold = X[(index + 1):]\n",
    "                y_testFold = y[(index + 1):]\n",
    "                \n",
    "                reg=algorithm(**a)\n",
    "                reg.fit(X_trainFolds, y_trainFolds)\n",
    "                \n",
    "                y_predict=reg.predict(X_testFold)\n",
    "                accuracies[t-2]=accuracy_score(y_testFold,y_predict)\n",
    "            #print(accuracies.mean())\n",
    "            info=[]\n",
    "            info.append(list(params.values())[0][i])\n",
    "            info.append(list(params.values())[1][j])\n",
    "            total[str(accuracies.mean())]=info\n",
    "    compare=[]\n",
    "    for i in total.keys():\n",
    "        compare.append(float(i))\n",
    "    Best_accu=max(compare)\n",
    "    print('Best accuracy:',Best_accu)\n",
    "    print(list(params.keys())[0],':',total[str(Best_accu)][0])\n",
    "    print(list(params.keys())[1],':',total[str(Best_accu)][1])\n",
    "    fin_params=params_fix\n",
    "    fin_params[list(params.keys())[0]]=total[str(Best_accu)][0]\n",
    "    fin_params[list(params.keys())[1]]=total[str(Best_accu)][1]\n",
    "    return fin_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict_values' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-c04d21e25e7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpara\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mperformTimeSeriesCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'min_samples_split'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-820f7058c796>\u001b[0m in \u001b[0;36mperformTimeSeriesCV\u001b[1;34m(X_train, y_train, number_folds, algorithm, params_fix, params)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams_fix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'dict_values' object does not support indexing"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "para=performTimeSeriesCV(X_train, y_train, 10, RandomForestClassifier,{},{'n_estimators':[120,150],'min_samples_split':[2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 150, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=120, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=RandomForestClassifier(n_estimators=120)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.516\n"
     ]
    }
   ],
   "source": [
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "performTimeSeriesCV() missing 1 required positional argument: 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-3cf5367a8de7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpara\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mperformTimeSeriesCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'n_neighbors'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m26\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m27\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'leaf_size'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: performTimeSeriesCV() missing 1 required positional argument: 'params'"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "para=performTimeSeriesCV(X_train, y_train, 10, KNeighborsClassifier,{'n_neighbors':[23,24,25,26,27,28],'leaf_size':[30]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=25, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=KNeighborsClassifier(n_neighbors=25)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.532\n"
     ]
    }
   ],
   "source": [
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best accuracy:', 0.542251786154)\n",
      "('C', ':', 400)\n",
      "('degree', ':', 900)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "performTimeSeriesCV(X_train, y_train, 10, SVC,{'C':[200,300,400,500,600,700,800,900],'degree':[200,300,400,500,600,700,800,900]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=400, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=900, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model=SVC(C=400,degree=900)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.512\n"
     ]
    }
   ],
   "source": [
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best accuracy:', 0.535353535354)\n",
      "('n_estimators', ':', 77)\n",
      "('learning_rate', ':', 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import  AdaBoostClassifier\n",
    "performTimeSeriesCV(X_train, y_train, 10, AdaBoostClassifier,{'n_estimators':[72,73,74,75,76,77,78],'learning_rate':[2,2.5,3,3.5,4,4.5,5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=4,\n",
       "          n_estimators=77, random_state=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=AdaBoostClassifier(n_estimators=77,learning_rate=4)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.478\n"
     ]
    }
   ],
   "source": [
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.508\n"
     ]
    }
   ],
   "source": [
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "5.2 Fix learning rate and number of estimators for tuning tree-based parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best accuracy:', 0.522296132052)\n",
      "('n_estimators', ':', 30)\n",
      "('learning_rate', ':', 0.1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model=GradientBoostingClassifier(learning_rate=0.1, min_samples_split=100,min_samples_leaf=50,max_depth=8,max_features='sqrt',subsample=0.8,random_state=10)\n",
    "performTimeSeriesCV(X_train, y_train, 10,\n",
    "                    GradientBoostingClassifier,\n",
    "                    {'min_samples_split':100,'min_samples_leaf':50,'max_depth':8,'max_features':'sqrt','subsample':0.8,'random_state':10},\n",
    "                    {'n_estimators':[20,30,40,50,60,70,80],'learning_rate':[0.1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=8,\n",
       "              max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=50,\n",
       "              min_samples_split=100, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=30, presort='auto', random_state=10,\n",
       "              subsample=0.8, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params={'n_estimators':30,'learning_rate':0.1,'min_samples_split':100,'min_samples_leaf':50,'max_depth':8,'max_features':'sqrt','subsample':0.8,'random_state':10}\n",
    "model=GradientBoostingClassifier(**params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.512\n"
     ]
    }
   ],
   "source": [
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3 Tune max_depth and num_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict_values' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d4e3807530cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[1;33m{\u001b[0m\u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'learning_rate'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'min_samples_leaf'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'max_features'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'sqrt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'subsample'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'random_state'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                     {'max_depth':[5,7,9,11,13,15],'min_samples_split':[200,400,600,800,1000]})\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-820f7058c796>\u001b[0m in \u001b[0;36mperformTimeSeriesCV\u001b[1;34m(X_train, y_train, number_folds, algorithm, params_fix, params)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams_fix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'dict_values' object does not support indexing"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "params=performTimeSeriesCV(X_train, y_train, 10,\n",
    "                    GradientBoostingClassifier,\n",
    "                    {'n_estimators':30,'learning_rate':0.1,'min_samples_leaf':50,'max_features':'sqrt','subsample':0.8,'random_state':10},\n",
    "                    {'max_depth':[5,7,9,11,13,15],'min_samples_split':[200,400,600,800,1000]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best accuracy:', 0.525006159153)\n",
      "('min_samples_split', ':', 150)\n",
      "('max_depth', ':', 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "params=performTimeSeriesCV(X_train, y_train, 10,\n",
    "                    GradientBoostingClassifier,\n",
    "                    {'n_estimators':30,'learning_rate':0.1,'min_samples_leaf':50,'max_features':'sqrt','subsample':0.8,'random_state':10},\n",
    "                    {'max_depth':[6,7,8],'min_samples_split':[50,100,150,200]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best accuracy:', 0.532150776053)\n",
      "('min_samples_split', ':', 120)\n",
      "('max_depth', ':', 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "params=performTimeSeriesCV(X_train, y_train, 10,\n",
    "                    GradientBoostingClassifier,\n",
    "                    {'n_estimators':30,'learning_rate':0.1,'min_samples_leaf':50,'max_features':'sqrt','subsample':0.8,'random_state':10},\n",
    "                    {'max_depth':[8],'min_samples_split':[100,120,130,140,150]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'min_samples_leaf': 50, 'n_estimators': 30, 'subsample': 0.8, 'random_state': 10, 'max_features': 'sqrt', 'min_samples_split': 120, 'max_depth': 8}\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=8,\n",
       "              max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=50,\n",
       "              min_samples_split=120, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=30, presort='auto', random_state=10,\n",
       "              subsample=0.8, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=GradientBoostingClassifier(**params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.528\n"
     ]
    }
   ],
   "source": [
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.4 Tune min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best accuracy:', 0.531165311653)\n",
      "('min_samples_split', ':', 120)\n",
      "('min_samples_leaf', ':', 40)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "params=performTimeSeriesCV(X_train, y_train, 10,\n",
    "                    GradientBoostingClassifier,\n",
    "                    {'n_estimators':30,'learning_rate':0.1,'min_samples_leaf':50,'max_features':'sqrt','subsample':0.8,'random_state':10},\n",
    "                    {'min_samples_split':[120],'min_samples_leaf':[30,40,50,60,70]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'min_samples_leaf': 40, 'n_estimators': 30, 'subsample': 0.8, 'random_state': 10, 'max_features': 'sqrt', 'min_samples_split': 120}\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=40,\n",
       "              min_samples_split=120, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=30, presort='auto', random_state=10,\n",
       "              subsample=0.8, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=GradientBoostingClassifier(**params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.536\n"
     ]
    }
   ],
   "source": [
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.5 Tune max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best accuracy:', 0.526730721853)\n",
      "('max_features', ':', 19)\n",
      "('min_samples_leaf', ':', 40)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "params=performTimeSeriesCV(X_train, y_train, 10,\n",
    "                    GradientBoostingClassifier,\n",
    "                    {'learning_rate': 0.1, 'min_samples_leaf': 40, 'n_estimators': 30, 'subsample': 0.8, 'random_state': 10, 'max_features': 'sqrt', 'min_samples_split': 120},\n",
    "                    {'min_samples_leaf':[40],'max_features':[7,9,11,13,15,17,19,21]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best accuracy:', 0.526730721853)\n",
      "('max_features', ':', 19)\n",
      "('min_samples_leaf', ':', 40)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "params=performTimeSeriesCV(X_train, y_train, 10,\n",
    "                    GradientBoostingClassifier,\n",
    "                    {'learning_rate': 0.1, 'min_samples_leaf': 40, 'n_estimators': 30, 'subsample': 0.8, 'random_state': 10, 'max_features': 'sqrt', 'min_samples_split': 120},\n",
    "                    {'min_samples_leaf':[40],'max_features':[17,18,19,20,21,22,23]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best accuracy:', 0.527469820153)\n",
      "('max_features', ':', 57)\n",
      "('min_samples_leaf', ':', 40)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "params=performTimeSeriesCV(X_train, y_train, 10,\n",
    "                    GradientBoostingClassifier,\n",
    "                    {'learning_rate': 0.1, 'min_samples_leaf': 40, 'n_estimators': 30, 'subsample': 0.8, 'random_state': 10, 'max_features': 'sqrt', 'min_samples_split': 120},\n",
    "                    {'min_samples_leaf':[40],'max_features':[7,19,27,37,47,57,67,77,87]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best accuracy:', 0.527469820153)\n",
      "('max_features', ':', 57)\n",
      "('min_samples_leaf', ':', 40)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "params=performTimeSeriesCV(X_train, y_train, 10,\n",
    "                    GradientBoostingClassifier,\n",
    "                    {'learning_rate': 0.1, 'min_samples_leaf': 40, 'n_estimators': 30, 'subsample': 0.8, 'random_state': 10, 'max_features': 'sqrt', 'min_samples_split': 120},\n",
    "                    {'min_samples_leaf':[40],'max_features':[7,19,27,37,47,57,67,77,87,97,107,117,127]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'min_samples_leaf': 40, 'n_estimators': 30, 'subsample': 0.8, 'random_state': 10, 'max_features': 57, 'min_samples_split': 120}\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=57, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=40,\n",
       "              min_samples_split=120, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=30, presort='auto', random_state=10,\n",
       "              subsample=0.8, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=GradientBoostingClassifier(**params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.538\n"
     ]
    }
   ],
   "source": [
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.6 Tuning subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best accuracy:', 0.534368070953)\n",
      "('max_features', ':', 57)\n",
      "('subsample', ':', 0.88)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "params=performTimeSeriesCV(X_train, y_train, 10,\n",
    "                    GradientBoostingClassifier,\n",
    "                    {'learning_rate': 0.1, 'min_samples_leaf': 40, 'n_estimators': 30, 'subsample': 0.8, 'random_state': 10, 'max_features': 57, 'min_samples_split': 120},\n",
    "                    {'subsample':[0.81,0.82,0.83,0.84,0.85,0.86,0.87,0.88,0.89],'max_features':[57]})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best accuracy:', 0.527469820153)\n",
      "('max_features', ':', 57)\n",
      "('subsample', ':', 0.8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "params=performTimeSeriesCV(X_train, y_train, 10,\n",
    "                    GradientBoostingClassifier,\n",
    "                    {'learning_rate': 0.1, 'min_samples_leaf': 40, 'n_estimators': 30, 'subsample': 0.8, 'random_state': 10, 'max_features': 57, 'min_samples_split': 120},\n",
    "                    {'subsample':[0.77,0.78,0.79,0.80,0.81,0.82,0.83],'max_features':[57]})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'min_samples_leaf': 40, 'n_estimators': 30, 'subsample': 0.8, 'random_state': 10, 'max_features': 57, 'min_samples_split': 120}\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=57, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=40,\n",
       "              min_samples_split=120, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=30, presort='auto', random_state=10,\n",
       "              subsample=0.8, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=GradientBoostingClassifier(**params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.538\n"
     ]
    }
   ],
   "source": [
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "5.7 lower learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params={'learning_rate': 0.1, 'min_samples_leaf': 40, 'n_estimators': 30, 'subsample': 0.8, 'random_state': 10, 'max_features': 57, 'min_samples_split': 120}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=57, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=40,\n",
       "              min_samples_split=120, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=30, presort='auto', random_state=10,\n",
       "              subsample=0.8, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=GradientBoostingClassifier(**params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.538\n"
     ]
    }
   ],
   "source": [
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "6 QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanhuan/anaconda/envs/tensorflow/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:695: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
       "               store_covariances=False, tol=0.0001)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "model=QuadraticDiscriminantAnalysis()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.496\n"
     ]
    }
   ],
   "source": [
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=8,\n",
       "              max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=50,\n",
       "              min_samples_split=120, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=30, presort='auto', random_state=10,\n",
       "              subsample=0.8, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=GradientBoostingClassifier(**params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "7 SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best accuracy:', 0.539049026854)\n",
      "('n_iter', ':', 10)\n",
      "('l1_ratio', ':', 0.17)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "performTimeSeriesCV(X_train, y_train, 10, SGDClassifier,{'n_iter':[3,5,7,10,13,15],'l1_ratio':[0.13,0.14,0.15,0.16,0.17,0.18]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.17,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=10, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=SGDClassifier(n_iter=10,l1_ratio=0.17)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.492\n"
     ]
    }
   ],
   "source": [
    "y_predict=model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RandomForestClassifier(n_estimators=120)           0.53\n",
    "KNeighborsClassifier(n_neighbors=25)               0.532\n",
    "SVC(C=400,degree=900)                              0.532\n",
    "AdaBoostClassifier(n_estimators=77,learning_rate=4)0.478"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator,TransformerMixin, ClassifierMixin\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.linear_model import ElasticNetCV, LassoLarsCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Train the stacked models then predict the test data'''\n",
    "#ORIGINAL\n",
    "class StackingEstimator(BaseEstimator, TransformerMixin):\n",
    "        \n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.estimator.fit(X, y, **fit_params)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = check_array(X)\n",
    "        X_transformed = np.copy(X)\n",
    "        # add class probabilities as a synthetic feature\n",
    "        if issubclass(self.estimator.__class__, ClassifierMixin) and hasattr(self.estimator, 'predict_proba'):\n",
    "            X_transformed = np.hstack((self.estimator.predict_proba(X), X))\n",
    "\n",
    "        # add class prodiction as a synthetic feature\n",
    "        X_transformed = np.hstack((np.reshape(self.estimator.predict(X), (-1, 1)), X_transformed))\n",
    "\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "params={'learning_rate': 0.1, 'min_samples_leaf': 40, 'n_estimators': 30, 'subsample': 0.8, 'random_state': 10, 'max_features': 57, 'min_samples_split': 120}\n",
    "stacked_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=RandomForestClassifier(n_estimators=120)),\n",
    "    StackingEstimator(estimator=GradientBoostingClassifier(**params)),\n",
    "    RandomForestClassifier(n_estimators=120)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.528\n"
     ]
    }
   ],
   "source": [
    "stacked_pipeline.fit(X_train, y_train)\n",
    "y_predict=stacked_pipeline.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
